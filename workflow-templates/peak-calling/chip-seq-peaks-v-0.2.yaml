# See the NOTICE file distributed with this work for additional information
# regarding copyright ownership.
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
# http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

apiVersion: argoproj.io/v1alpha1
kind: WorkflowTemplate
metadata:
  name: chip-seq-peaks-v-0.2.0
  annotations:
    workflows.argoproj.io/description: |
      Genrich re-runs from Genrich pq_values to generate peaks tracks for ChIP-seq experiments.
      Support for narrow and broad peaks.
spec:
  entrypoint: peak-calling-chip-seq

  templates:
    - name: peak-calling-chip-seq
      parallelism: 50
      inputs:
        parameters:
          - name: peak-calling-tasks
          #### Genrich parameters ####
          - name: genrich-params-narrow
          #            value: |
          #              {
          #                "a": null,
          #                "q_val": null,
          #                "p_val": 0.05,
          #                "g": null
          #              }
          - name: genrich-params-broad
          #            value: |
          #              {
          #                "a": 800,
          #                "q_val": null,
          #                "p_val": 0.1,
          #                "g": 200
          #              }
          ############################
          - name: overwrite-results
            value: "false"
          - name: production-run
            value: "false"
      dag:
        tasks:
          - name: execute-peak-calling-task
            template: peak-calling-task
            arguments:
              parameters:
                - name: task-payload
                  value: "{{item}}"
                - name: genrich-params-narrow
                  value: "{{inputs.parameters.genrich-params-narrow}}"
                - name: genrich-params-broad
                  value: "{{inputs.parameters.genrich-params-broad}}"
                - name: overwrite-results
                  value: "{{inputs.parameters.overwrite-results}}"
                - name: production-run
                  value: "{{inputs.parameters.production-run}}"
            withParam: "{{inputs.parameters.peak-calling-tasks}}"

    - name: peak-calling-task
      parallelism: 8
      inputs:
        parameters:
          - name: task-payload
          - name: genrich-params-narrow
          - name: genrich-params-broad
          - name: overwrite-results
          - name: production-run
      dag:
        tasks:
          - name: get-s3-keys-and-set-of-genrich-cmds
            template: compute-peak-calling-outputs-s3-keys
            arguments:
              parameters:
                - name: task-payload
                  value: "{{inputs.parameters.task-payload}}"
                - name: genrich-params-narrow
                  value: "{{inputs.parameters.genrich-params-narrow}}"
                - name: genrich-params-broad
                  value: "{{inputs.parameters.genrich-params-broad}}"

          #          -  name: check-if-outputs-exist-broad-case
          #            when: "{{=jsonpath(inputs.parameters['task-payload'], '$.broad_peaks')}} == true"
          #            depends: get-s3-keys-and-set-of-genrich-cmds.Succeeded
          #            templateRef:
          #              name: check-if-s3-objects-exist-v1-submittable
          #              template: check-if-s3-objects-exist
          #            arguments:
          #              parameters:
          #                - name: s3-keys
          #                  value: |
          #                    [
          #                      "{{tasks.get-s3-keys-and-set-of-genrich-cmds.outputs.parameters.narrow-peaks-s3-key}}",
          #                      "{{tasks.get-s3-keys-and-set-of-genrich-cmds.outputs.parameters.broad-peaks-s3-key}}",
          #                      "{{tasks.get-s3-keys-and-set-of-genrich-cmds.outputs.parameters.gapped-peaks-s3-key}}"
          #                    ]

          # TODO: Refactor this part to include check for broad specific outputs
          - name: check-if-outputs-exist-narrow-case
            #            when: "{{=jsonpath(inputs.parameters['task-payload'], '$.broad_peaks')}} == false"
            depends: get-s3-keys-and-set-of-genrich-cmds.Succeeded
            templateRef:
              name: check-if-s3-objects-exist-v-0.1.0
              template: check-if-s3-objects-exist
            arguments:
              parameters:
                - name: s3-keys
                  value: |
                    [
                      "{{tasks.get-s3-keys-and-set-of-genrich-cmds.outputs.parameters.narrow-peaks-s3-key}}"
                    ]

          - name: get-peak-calling-pvc-size
            depends: check-if-outputs-exist-narrow-case.Succeeded
            when: >-
              {{tasks.check-if-outputs-exist-narrow-case.outputs.parameters.check-response}} == false
            templateRef:
              name: compute-pvc-size-v-0.1.0
              template: compute-pvc-size
            arguments:
              parameters:
                - name: associated_files_size
                  value: "{{=jsonpath(inputs.parameters['task-payload'], '$.pq_values_file_size')}}"
                - name: size_factor
                  value: "2.8"

          - name: create-peak-calling-pvc
            depends: get-peak-calling-pvc-size.Succeeded
            templateRef:
              name: create-pvc-v-0.2.0
              template: create-pvc
            arguments:
              parameters:
                - name: pvc-size
                  value: "{{tasks.get-peak-calling-pvc-size.outputs.parameters.pvc-size-formatted}}"

          - name: load-pq-values-to-pvc
            depends: create-peak-calling-pvc.Succeeded
            templateRef:
              name: s3-object-to-pvc-v-0.1.0
              template: s3-object-to-pvc
            arguments:
              parameters:
                - name: s3-key
                  value: "{{=jsonpath(inputs.parameters['task-payload'], '$.pq_values_s3_key')}}"
                - name: filename
                  value: "{{=sprig.base(jsonpath(inputs.parameters['task-payload'], '$.pq_values_s3_key'))}}"
                - name: pvc-name
                  value: "{{tasks.create-peak-calling-pvc.outputs.parameters.pvc-name}}"

          - name: decompress-pq-values
            depends: load-pq-values-to-pvc.Succeeded
            templateRef:
              name: decompress-tgz-pvc-callable-v-0.1.0
              template: decompress-tgz-pvc-callable
            arguments:
              parameters:
                - name: pvc-name
                  value: "{{tasks.create-peak-calling-pvc.outputs.parameters.pvc-name}}"
                - name: filename
                  value: "{{=sprig.base(jsonpath(inputs.parameters['task-payload'], '$.pq_values_s3_key'))}}"

          - name: execute-peak-calling-narrow-case
            depends: decompress-pq-values.Succeeded
            template: genrich-re-run-cmd
            arguments:
              parameters:
                - name: pq-values-pvc-name
                  value: "{{tasks.create-peak-calling-pvc.outputs.parameters.pvc-name}}"
                - name: pq-values-filename
                  value: "{{=sprig.trimSuffix('.tgz', sprig.base(jsonpath(inputs.parameters['task-payload'], '$.pq_values_s3_key')))}}"
                - name: params-cmd-string
                  value: "{{tasks.get-s3-keys-and-set-of-genrich-cmds.outputs.parameters.narrow-parameters-str}}"
                - name: out-s3-key
                  value: "{{tasks.get-s3-keys-and-set-of-genrich-cmds.outputs.parameters.narrow-peaks-s3-key}}"
                - name: out-filename
                  value: "{{=sprig.base(tasks['get-s3-keys-and-set-of-genrich-cmds'].outputs.parameters['narrow-peaks-s3-key'])}}"

          - name: output-narrow-bed-file-post-processing
            depends: execute-peak-calling-narrow-case.Succeeded
            when: "{{inputs.parameters.production-run}} == true"
            template: dag-bed-output-files-post-processing
            arguments:
              parameters:
                - name: task-payload
                  value: "{{inputs.parameters.task-payload}}"
                - name: peaks-s3-key
                  value: "{{tasks.get-s3-keys-and-set-of-genrich-cmds.outputs.parameters.narrow-peaks-s3-key}}"
                - name: analysis-type
                  value: "{{=jsonpath(inputs.parameters['task-payload'], '$.experiment_type')}}_narrow_peaks"


          - name: save-narrow-case-genrich-logs
            depends: execute-peak-calling-narrow-case.Succeeded
            templateRef:
              name: cp-s3-object-to-s3-v-0.1.0
              template: cp-s3-object-to-s3
            arguments:
              parameters:
                - name: in-s3-key
                  value: "{{tasks.execute-peak-calling-narrow-case.outputs.parameters.genrich-run-logs-s3-key}}"
                - name: out-s3-key
                  value: "{{=sprig.trimSuffix('.bed', tasks['get-s3-keys-and-set-of-genrich-cmds'].outputs.parameters['narrow-peaks-s3-key'])}}.log"

          - name: execute-peak-calling-broad-case
            depends: execute-peak-calling-narrow-case.Succeeded
            when: "{{=jsonpath(inputs.parameters['task-payload'], '$.broad_peaks')}} == true"
            template: genrich-re-run-cmd
            arguments:
              parameters:
                - name: pq-values-pvc-name
                  value: "{{tasks.create-peak-calling-pvc.outputs.parameters.pvc-name}}"
                - name: pq-values-filename
                  value: "{{=sprig.trimSuffix('.tgz', sprig.base(jsonpath(inputs.parameters['task-payload'], '$.pq_values_s3_key')))}}"
                - name: params-cmd-string
                  value: "{{tasks.get-s3-keys-and-set-of-genrich-cmds.outputs.parameters.broad-parameters-str}}"
                - name: out-s3-key
                  value: "{{tasks.get-s3-keys-and-set-of-genrich-cmds.outputs.parameters.broad-peaks-s3-key}}"
                - name: out-filename
                  value: "{{=sprig.base(tasks['get-s3-keys-and-set-of-genrich-cmds'].outputs.parameters['broad-peaks-s3-key'])}}"

          - name: output-broad-bed-file-post-processing
            depends: execute-peak-calling-broad-case.Succeeded
            when: "{{inputs.parameters.production-run}} == true"
            template: dag-bed-output-files-post-processing
            arguments:
              parameters:
                - name: task-payload
                  value: "{{inputs.parameters.task-payload}}"
                - name: peaks-s3-key
                  value: "{{tasks.get-s3-keys-and-set-of-genrich-cmds.outputs.parameters.broad-peaks-s3-key}}"
                - name: analysis-type
                  value: "{{=jsonpath(inputs.parameters['task-payload'], '$.experiment_type')}}_broad_peaks"

          - name: save-broad-case-genrich-logs
            depends: execute-peak-calling-broad-case.Succeeded
            templateRef:
              name: cp-s3-object-to-s3-v-0.1.0
              template: cp-s3-object-to-s3
            arguments:
              parameters:
                - name: in-s3-key
                  value: "{{tasks.execute-peak-calling-broad-case.outputs.parameters.genrich-run-logs-s3-key}}"
                - name: out-s3-key
                  value: "{{=sprig.trimSuffix('.bed', tasks['get-s3-keys-and-set-of-genrich-cmds'].outputs.parameters['broad-peaks-s3-key'])}}.log"

          - name: execute-write-gapped-peaks
            depends: execute-peak-calling-broad-case.Succeeded
            template: write-gapped-peaks
            arguments:
              parameters:
                - name: narrow-peaks-s3-key
                  value: "{{tasks.get-s3-keys-and-set-of-genrich-cmds.outputs.parameters.narrow-peaks-s3-key}}"
                - name: broad-peaks-s3-key
                  value: "{{tasks.get-s3-keys-and-set-of-genrich-cmds.outputs.parameters.broad-peaks-s3-key}}"
                - name: gapped-peaks-s3-key
                  value: "{{tasks.get-s3-keys-and-set-of-genrich-cmds.outputs.parameters.gapped-peaks-s3-key}}"

          - name: output-gapped-bed-file-post-processing
            depends: execute-write-gapped-peaks.Succeeded
            when: "{{inputs.parameters.production-run}} == true"
            template: dag-bed-output-files-post-processing
            arguments:
              parameters:
                - name: task-payload
                  value: "{{inputs.parameters.task-payload}}"
                - name: peaks-s3-key
                  value: "{{tasks.get-s3-keys-and-set-of-genrich-cmds.outputs.parameters.gapped-peaks-s3-key}}"
                - name: analysis-type
                  value: "{{=jsonpath(inputs.parameters['task-payload'], '$.experiment_type')}}_gapped_peaks"


          - name: delete-peak-calling-pvc
            depends: execute-peak-calling-narrow-case.Succeeded && execute-peak-calling-broad-case
            templateRef:
              name: delete-pvc-v-0.1.0
              template: delete-pvc
            arguments:
              parameters:
                - name: pvc-name
                  value: "{{tasks.create-peak-calling-pvc.outputs.parameters.pvc-name}}"


    - name: genrich-re-run-cmd
      retryStrategy:
        limit: "5"
        backoff:
          duration: "10s"
          factor: "2"
          maxDuration: "12h"
        retryPolicy: "OnError"
      inputs:
        parameters:
          - name: pq-values-pvc-name
          - name: pq-values-filename
          - name: params-cmd-string

          - name: out-s3-key
          - name: out-filename
      container:
        image: dockerhub.ebi.ac.uk/ensreg/workflows/container-images/genrich:0.6.1
        workingDir: /mnt/vol
        securityContext:
          runAsUser: 0
          runAsNonRoot: false
        command: [ bash, -c, -uef, -o, xtrace ]
        args: [ "ls -altrh \
                && GENRICH_ARGS=(
                  -P \
                  -o {{inputs.parameters.out-filename}} \
                  -f {{inputs.parameters.pq-values-filename}} \
                  -v \
                ) \
                && GENRICH_ARGS+=( {{inputs.parameters.params-cmd-string}} ) \
                && Genrich ${GENRICH_ARGS[@]} \
                && echo aw-artifacts/\
               {{workflow.creationTimestamp.Y}}/\
               {{workflow.creationTimestamp.m}}/\
               {{workflow.creationTimestamp.d}}/\
               {{workflow.name}}/{{pod.name}}/\
               main.log \
               > genrich-run-logs-s3-key.txt \
                && ls -altrh" ]
        resources:
          limits:
            cpu: 1900m
            memory: 1.5Gi
          requests:
            cpu: 900m
            memory: 1Gi
        volumeMounts:
          - name: workdir
            mountPath: /mnt/vol
      volumes:
        - name: workdir
          persistentVolumeClaim:
            claimName: "{{inputs.parameters.pq-values-pvc-name}}"
      outputs:
        parameters:
          # TODO directly use variables here instead of getting the name from genrich-run-logs-s3-key.txt
          - name: genrich-run-logs-s3-key
            valueFrom:
              path: /mnt/vol/genrich-run-logs-s3-key.txt
        artifacts:
          - name: bed-file
            path: /mnt/vol/{{inputs.parameters.out-filename}}
            archive:
              none: { }
            s3:
              key: "{{inputs.parameters.out-s3-key}}"


    - name: compute-peak-calling-outputs-s3-keys
      retryStrategy:
        limit: "5"
        retryPolicy: "OnError"
      inputs:
        parameters:
          - name: task-payload
          - name: genrich-params-narrow
          - name: genrich-params-broad
      script:
        image: dockerhub.ebi.ac.uk/ensreg/workflows/container-images/python-wf-helper:3.11.7_0.1.0
        workingDir: /home/ensreg/workdir/
        command: [ python ]
        source: |
          import sys
          import json
          import logging
          import re
          
          from pprint import pprint
          from uuid import UUID
          
          from typing import (
            Optional,
            Union,
          )
          
          from pydantic import BaseModel, validator

          class PeakCallingTaskReRun(BaseModel):
            epigenome_name: str
            experiment_name: str
            experiment_id: UUID
            assembly_id: UUID
            experiment_type: str
            pq_values_s3_key: str
            pq_values_file_size: int
            pq_values_md5sum: str
            out_basename: str
            out_s3_prefix: str
            broad_peaks: Union[bool, None] = None
          
            @property
            def experiment_type_formatted(self) -> str:
              return re.sub('_', '-', self.experiment_type)
          
          
          class GenrichParams(BaseModel):
            a: Optional[float]
            q_val: Optional[float]
            p_val: Optional[float]
            g: Optional[int]
          
            @validator('p_val')
            def ignore_p_val(cls, v, values):
              if 'q_val' in values and values['q_val'] is not None:
                logging.warning('Ignoring p_val parameter because q_val was provided') 
                return None
              return v
          
            @property
            def cmd_portion(self) -> str:
              params_cmd_portion = ""
              if self.a is not None:
                params_cmd_portion += f"-a {self.a} "
              if self.q_val is not None:
                params_cmd_portion += f"-q {self.q_val} "
              if self.p_val is not None:
                params_cmd_portion += f"-p {self.p_val} "
              if self.g is not None:
                params_cmd_portion += f"-g {self.g} "
              return params_cmd_portion
          
            @property
            def suffix_portion(self) -> str:
              params_suffix_portion = ""
              if self.a is not None:
                  params_suffix_portion += f"_a_{self.a}"
              if self.q_val is not None:
                  params_suffix_portion += f"_q_{self.q_val}"
              if self.p_val is not None:
                  params_suffix_portion += f"_p_{self.p_val}"
              if self.g is not None:
                  params_suffix_portion += f"_g_{self.g}"
          
              params_suffix_portion = re.sub('\.', '_', params_suffix_portion)
          
              return params_suffix_portion
          
          
          def main() -> int:
          
            task_payload = """{{inputs.parameters.task-payload}}"""
            genrich_params_narrow = """{{inputs.parameters.genrich-params-narrow}}"""
            genrich_params_broad = """{{inputs.parameters.genrich-params-broad}}"""
          
            task_payload_data = json.loads(task_payload)
            genrich_params_narrow_data = json.loads(genrich_params_narrow)
            genrich_params_broad_data = json.loads(genrich_params_broad)
          
          
            task = PeakCallingTaskReRun(**task_payload_data)
            params_narrow = GenrichParams(**genrich_params_narrow_data)
            params_broad = GenrichParams(**genrich_params_broad_data)

            # TODO: Refactor this part
            with open("narrow_params_str.txt", 'w') as f:
                f.write(params_narrow.cmd_portion)
          
            with open("broad_params_str.txt", 'w') as f:  
                f.write(params_broad.cmd_portion)
          
            with open("narrow_s3_key.txt", 'w') as f:
                f.write(f"{task.out_s3_prefix}{task.experiment_type_formatted}-narrow-peaks-{task.out_basename}{params_narrow.suffix_portion}.bed")
          
            with open("broad_s3_key.txt", 'w') as f:
                f.write(f"{task.out_s3_prefix}{task.experiment_type_formatted}-broad-peaks-{task.out_basename}{params_broad.suffix_portion}.bed")
          
            with open("gapped_s3_key.txt", 'w') as f:
                f.write(f"{task.out_s3_prefix}{task.experiment_type_formatted}-gapped-peaks-{task.out_basename}_n{params_narrow.suffix_portion}_b{params_broad.suffix_portion}.bed")
          
            return 0
          
          if __name__ == '__main__':
              sys.exit(main())

      outputs:
        parameters:
          - name: narrow-parameters-str
            valueFrom:
              path: /home/ensreg/workdir/narrow_params_str.txt
          - name: broad-parameters-str
            valueFrom:
              path: /home/ensreg/workdir/broad_params_str.txt
          - name: narrow-peaks-s3-key
            valueFrom:
              path: /home/ensreg/workdir/narrow_s3_key.txt
          - name: broad-peaks-s3-key
            valueFrom:
              path: /home/ensreg/workdir/broad_s3_key.txt
          - name: gapped-peaks-s3-key
            valueFrom:
              path: /home/ensreg/workdir/gapped_s3_key.txt


    - name: write-gapped-peaks
      retryStrategy:
        limit: "5"
        backoff:
          duration: "10s"
          factor: "2"
          maxDuration: "12h"
        retryPolicy: "Always"
      inputs:
        parameters:
          - name: narrow-peaks-s3-key
          - name: broad-peaks-s3-key
          - name: gapped-peaks-s3-key
        artifacts:
          - name: narrow_peaks_file
            path: "/home/ensreg/workdir/{{=sprig.base(inputs.parameters['narrow-peaks-s3-key'])}}"
            s3:
              key: "{{inputs.parameters.narrow-peaks-s3-key}}"
          - name: broad_peaks_file
            path: "/home/ensreg/workdir/{{=sprig.base(inputs.parameters['broad-peaks-s3-key'])}}"
            s3:
              key: "{{inputs.parameters.broad-peaks-s3-key}}"
      container:
        image: dockerhub.ebi.ac.uk/ensreg/workflows/container-images/ensreg-gapped-peaks:3.10.12_0.1.0
        command: [ bash, -c, -uef, -o, xtrace ]
        args: [ " ls -altrh \
              && python writeGappedPeaks.py \
              {{=sprig.base(inputs.parameters['broad-peaks-s3-key'])}} \
              {{=sprig.base(inputs.parameters['narrow-peaks-s3-key'])}} \
              {{=sprig.base(inputs.parameters['gapped-peaks-s3-key'])}}" ]
        resources:
          limits:
            cpu: 1200m
            memory: 10Gi
          requests:
            cpu: 900m
            memory: 1Gi

      outputs:
        artifacts:
          - name: gapped_peaks_file
            path: "/home/ensreg/workdir/{{=sprig.base(inputs.parameters['gapped-peaks-s3-key'])}}"
            archive:
              none: { }
            s3:
              key: "{{inputs.parameters.gapped-peaks-s3-key}}"

    - name: dag-bed-output-files-post-processing
      parallelism: 1
      inputs:
        parameters:
          - name: task-payload
          - name: peaks-s3-key
          - name: analysis-type
      dag:
        tasks:
          - name: compute-output-file-metadata
            templateRef:
              name: compute-file-metadata-v-0.1.0
              template: compute-file-metadata
            arguments:
              parameters:
                - name: s3-key
                  value: "{{inputs.parameters.peaks-s3-key}}"
                - name: filename
                  value: "{{=sprig.base(inputs.parameters['peaks-s3-key'])}}"

          - name: get-output-file-post-request-payload
            depends: compute-output-file-metadata.Succeeded
            templateRef:
              name: analysis-file-post-request-payload-v-0.1.0
              template: analysis-file-post-request-payload
            arguments:
              parameters:
                - name: s3-key
                  value: "{{inputs.parameters.peaks-s3-key}}"
                - name: basename
                  value: "{{=sprig.trimSuffix('.bed', sprig.base(inputs.parameters['peaks-s3-key']))}}"
                - name: file-size
                  value: "{{tasks.compute-output-file-metadata.outputs.parameters.file-size}}"
                - name: md5sum
                  value: "{{tasks.compute-output-file-metadata.outputs.parameters.md5sum}}"
                - name: experiment-id
                  value: "{{=jsonpath(inputs.parameters['task-payload'], '$.experiment_id')}}"
                - name: assembly-id
                  value: "{{=jsonpath(inputs.parameters['task-payload'], '$.assembly_id')}}"
                - name: analysis-type
                  value: "{{inputs.parameters.analysis-type}}"
