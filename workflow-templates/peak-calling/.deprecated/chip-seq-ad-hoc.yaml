# See the NOTICE file distributed with this work for additional information
# regarding copyright ownership.
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
# http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

apiVersion: argoproj.io/v1alpha1
kind: WorkflowTemplate
metadata:
  name: peak-calling-chip-seq-ad-hoc-v1-submittable
spec:
  entrypoint: peak-calling-chip-seq
  imagePullSecrets:
    - name: ghcr-pull-token

  templates:
    - name: peak-calling-chip-seq
      parallelism: 8
      inputs:
        parameters:
          - name: peak_calling_tasks
          - name: masked_regions_prefix
          - name: masked_regions_filename
          - name: a
          - name: q
          - name: p_value_narrow
          - name: p_value_broad
          - name: overwrite-results
          - name: kubeconfig-path
      dag:
        tasks:
          - name: execute-peak-calling-task
            template: peak-calling-task
            arguments:
              parameters:
                - name: task_payload
                  value: "{{item}}"
                - name: masked_regions_prefix
                  value: "{{inputs.parameters.masked_regions_prefix}}"
                - name: masked_regions_filename
                  value: "{{inputs.parameters.masked_regions_filename}}"
                - name: a
                  value: "{{inputs.parameters.a}}"
                - name: q
                  value: "{{inputs.parameters.q}}"
                - name: p_value_narrow
                  value: "{{inputs.parameters.p_value_narrow}}"
                - name: p_value_broad
                  value: "{{inputs.parameters.p_value_broad}}"
                - name: overwrite-results
                  value: "{{inputs.parameters.overwrite-results}}"
                - name: kubeconfig-path
                  value: "{{inputs.parameters.kubeconfig-path}}"
                - name: force-update-task-markers
                  value: "false"
            withParam: "{{inputs.parameters.peak_calling_tasks}}"


    - name: peak-calling-task
      parallelism: 1
      inputs:
        parameters:
          - name: task_payload
          - name: masked_regions_prefix
          - name: masked_regions_filename
          - name: a
          - name: q
          - name: p_value_narrow
          - name: p_value_broad
          - name: overwrite-results
          - name: kubeconfig-path
          - name: force-update-task-markers

      dag:
        tasks:
          - name: compute-peak-calling-task-marker-name
            templateRef:
              name: compute-task-marker-name-v1-submittable
              template: compute-task-marker-name
            arguments:
              parameters:
                - name: task-payload
                  value: "{{inputs.parameters.task_payload}}"
                - name: task-type
                  value: "peak-calling"

          - name: check-if-task-marker-exists
            depends: compute-peak-calling-task-marker-name
            templateRef:
              name: check-s3-object-exists-v1-submittable
              template: check-s3-object-exists
            arguments:
              parameters:
                - name: s3-key
                  value: "{{tasks.compute-peak-calling-task-marker-name.outputs.result}}"

          - name: check-if-bed-file-already-in-s3-bucket
            templateRef:
              name: check-s3-object-exists-v1-submittable
              template: check-s3-object-exists
            arguments:
              parameters:
                - name: s3-key
                  value: "{{=jsonpath(inputs.parameters.task_payload, '$.out_s3_prefix')}}{{=jsonpath(inputs.parameters.task_payload, '$.out_basename')}}.bed"

          - name: check-work-avoidance-consistency
            depends: "check-if-task-marker-exists && check-if-bed-file-already-in-s3-bucket"
            templateRef:
              name: resolve-work-avoidance-v1-submittable
              template: resolve-work-avoidance
            arguments:
              parameters:
                - name: marker-exists
                  value: "{{tasks.check-if-task-marker-exists.outputs.parameters.s3-object-exists}}"
                - name: output-artifact-exists
                  value: "{{tasks.check-if-bed-file-already-in-s3-bucket.outputs.parameters.s3-object-exists}}"
                - name: overwrite-results
                  value: "{{inputs.parameters.overwrite-results}}"

          - name: check-if-any-controls-present
            depends: check-work-avoidance-consistency.Succeeded
            when: "{{tasks.check-work-avoidance-consistency.outputs.parameters.avoid-work}} == false"
            templateRef:
              name: check-if-field-present-and-not-empty-v1-submittable
              template: check-if-field-present-and-not-empty
            arguments:
              parameters:
                - name: field-name
                  value: "controls"
                - name: task-payload
                  value: "{{inputs.parameters.task_payload}}"

          - name: get-genrich-input-filenames-formatted
            depends: check-work-avoidance-consistency.Succeeded
            when: "{{tasks.check-work-avoidance-consistency.outputs.parameters.avoid-work}} == false"
            template: edit-genrich-input-filenames-formatted
            arguments:
              parameters:
                - name: task_payload
                  value: "{{inputs.parameters.task_payload}}"

          - name: get-peak-calling-pvc-size
            depends: get-genrich-input-filenames-formatted
            when: "{{tasks.check-work-avoidance-consistency.outputs.parameters.avoid-work}} == false"
            templateRef:
              name: compute-pvc-size-v1-submittable
              template: compute-pvc-size
            arguments:
              parameters:
                - name: associated_files_size
                  value: "{{=jsonpath(inputs.parameters.task_payload, '$.alignment_files_total_size')}}"
                - name: size_factor
                  value: "4.5"

          - name: create-peak-calling-pvc
            depends: get-peak-calling-pvc-size.Succeeded
            templateRef:
              name: create-pvc-kubectl-v1-submittable
              template: create-pvc-kubectl
            arguments:
              parameters:
                - name: pvc-size
                  value: "{{tasks.get-peak-calling-pvc-size.outputs.parameters.pvc-size-formatted}}"
                - name: kubeconfig-path
                  value: "{{inputs.parameters.kubeconfig-path}}"

          - name: execute-sort-signal-alignments-by-queryname
            depends: create-peak-calling-pvc
            template: sort-alignments-by-queryname
            arguments:
              parameters:
                - name: sort_alignment_params
                  value: "{{item}}"
                # PVC in which to store so_queryname bams
                - name: out-pvc-name
                  value: "{{tasks.create-peak-calling-pvc.outputs.parameters.pvc-name}}"
                - name: kubeconfig-path
                  value: "{{inputs.parameters.kubeconfig-path}}"
            withParam: "{{=toJson(jsonpath(inputs.parameters.task_payload, '$.signals'))}}"

          - name: execute-sort-control-alignments-by-queryname
            depends: "execute-sort-signal-alignments-by-queryname && check-if-any-controls-present.Succeeded"
            when: "{{tasks.check-if-any-controls-present.outputs.parameters.controls-present}} == true"
            template: sort-alignments-by-queryname
            arguments:
              parameters:
                - name: sort_alignment_params
                  value: "{{item}}"
                # PVC in which to store so_queryname bams
                - name: out-pvc-name
                  value: "{{tasks.create-peak-calling-pvc.outputs.parameters.pvc-name}}"
                - name: kubeconfig-path
                  value: "{{inputs.parameters.kubeconfig-path}}"
            withParam: "{{=toJson(jsonpath(inputs.parameters.task_payload, '$.controls'))}}"

          - name: execute-genrich-chip-seq
            depends: "get-genrich-input-filenames-formatted && (execute-sort-signal-alignments-by-queryname && execute-sort-control-alignments-by-queryname)"
            template: genrich-chip-seq
            arguments:
              parameters:
                - name: masked_regions_prefix
                  value: "{{inputs.parameters.masked_regions_prefix}}"
                - name: masked_regions_filename
                  value: "{{inputs.parameters.masked_regions_filename}}"
                - name: q
                  value: "{{inputs.parameters.q}}"
                - name: signal_files_formatted_str
                  value: "{{tasks.get-genrich-input-filenames-formatted.outputs.parameters.signals_files_formatted_str}}"
                - name: control_files_formatted_str
                  value: "{{tasks.get-genrich-input-filenames-formatted.outputs.parameters.controls_files_formatted_str}}"
                - name: out_bed_filename
                  value: "{{=jsonpath(inputs.parameters.task_payload, '$.out_basename')}}.bed"
                - name: out_pileup_filename
                  value: "{{=jsonpath(inputs.parameters.task_payload, '$.out_basename')}}_pileup.log"
                - name: out_pq_file_filename
                  value: "{{=jsonpath(inputs.parameters.task_payload, '$.out_basename')}}_pqval.log"
                - name: out_s3_prefix
                  value: "{{=jsonpath(inputs.parameters.task_payload, '$.out_s3_prefix')}}"
                - name: alignments-pvc
                  value: "{{tasks.create-peak-calling-pvc.outputs.parameters.pvc-name}}"

          - name: execute-compute-bed-file-metadata
            depends: execute-genrich-chip-seq
            templateRef:
              name: compute-file-metadata-pvc-callable-v1-submittable
              template: compute-file-metadata-pvc-callable
            arguments:
              parameters:
                - name: pvc-name
                  value: "{{tasks.create-peak-calling-pvc.outputs.parameters.pvc-name}}"
                - name: filename
                  value: "{{=jsonpath(inputs.parameters.task_payload, '$.out_basename')}}.bed"

          - name: execute-post-peak-file
            depends: execute-compute-bed-file-metadata
            template: post-analysis-file
            arguments:
              parameters:
                - name: s3-key
                  value: "{{=jsonpath(inputs.parameters.task_payload, '$.out_s3_prefix')}}{{=jsonpath(inputs.parameters.task_payload, '$.out_basename')}}.bed"
                - name: basename
                  value: "{{=jsonpath(inputs.parameters.task_payload, '$.out_basename')}}"
                - name: file-size
                  value: "{{tasks.execute-compute-bed-file-metadata.outputs.parameters.file-size}}"
                - name: md5sum
                  value: "{{tasks.execute-compute-bed-file-metadata.outputs.parameters.md5sum}}"
                - name: experiment-id
                  value: "{{=jsonpath(inputs.parameters.task_payload, '$.experiment_id')}}"
                - name: assembly-id
                  value: "{{=jsonpath(inputs.parameters.task_payload, '$.assembly_id')}}"
                - name: analysis-type
                  value: "peaks"

          - name: execute-genrich-chip-seq-broad-peaks
            when: "true == {{=jsonpath(inputs.parameters.task_payload, '$.broad_peaks')}}"
            depends: execute-genrich-chip-seq
            template: genrich-chip-seq-broad-peaks
            arguments:
              parameters:
                - name: masked_regions_prefix
                  value: "{{inputs.parameters.masked_regions_prefix}}"
                - name: masked_regions_filename
                  value: "{{inputs.parameters.masked_regions_filename}}"
                - name: a
                  value: "{{inputs.parameters.a}}"
                - name: p_value_narrow
                  value: "{{inputs.parameters.p_value_narrow}}"
                - name: p_value_broad
                  value: "{{inputs.parameters.p_value_broad}}"
                - name: pileup-pvc
                  value: "{{tasks.create-peak-calling-pvc.outputs.parameters.pvc-name}}"
                - name: pileup_filename
                  value: "{{=jsonpath(inputs.parameters.task_payload, '$.out_basename')}}_pileup.log"
                - name: out_narrow_s3_prefix
                  value: "{{=jsonpath(inputs.parameters.task_payload, '$.out_s3_prefix')}}"
                - name: out_narrow_bed_filename
                  value: "narrow-{{=jsonpath(inputs.parameters.task_payload, '$.out_basename')}}.bed"
                - name: out_broad_s3_prefix
                  value: "{{=jsonpath(inputs.parameters.task_payload, '$.out_s3_prefix')}}"
                - name: out_broad_bed_filename
                  value: "broad-{{=jsonpath(inputs.parameters.task_payload, '$.out_basename')}}.bed"

          - name: execute-compute-narrow-bed-file-metadata
            depends: "execute-genrich-chip-seq-broad-peaks.Succeeded"
            templateRef:
              name: compute-file-metadata-pvc-callable-v1-submittable
              template: compute-file-metadata-pvc-callable
            arguments:
              parameters:
                - name: pvc-name
                  value: "{{tasks.create-peak-calling-pvc.outputs.parameters.pvc-name}}"
                - name: filename
                  value: "narrow-{{=jsonpath(inputs.parameters.task_payload, '$.out_basename')}}.bed"

          - name: execute-post-narrow-peaks-file
            depends: "execute-compute-narrow-bed-file-metadata"
            template: post-analysis-file
            arguments:
              parameters:
                - name: s3-key
                  value: "{{=jsonpath(inputs.parameters.task_payload, '$.out_s3_prefix')}}narrow-{{=jsonpath(inputs.parameters.task_payload, '$.out_basename')}}.bed"
                - name: basename
                  value: "narrow-{{=jsonpath(inputs.parameters.task_payload, '$.out_basename')}}"
                - name: file-size
                  value: "{{tasks.execute-compute-narrow-bed-file-metadata.outputs.parameters.file-size}}"
                - name: md5sum
                  value: "{{tasks.execute-compute-narrow-bed-file-metadata.outputs.parameters.md5sum}}"
                - name: experiment-id
                  value: "{{=jsonpath(inputs.parameters.task_payload, '$.experiment_id')}}"
                - name: assembly-id
                  value: "{{=jsonpath(inputs.parameters.task_payload, '$.assembly_id')}}"
                - name: analysis-type
                  value: "narrow_peaks"

          - name: execute-compute-broad-bed-file-metadata
            depends: "execute-genrich-chip-seq-broad-peaks.Succeeded"
            templateRef:
              name: compute-file-metadata-pvc-callable-v1-submittable
              template: compute-file-metadata-pvc-callable
            arguments:
              parameters:
                - name: pvc-name
                  value: "{{tasks.create-peak-calling-pvc.outputs.parameters.pvc-name}}"
                - name: filename
                  value: "broad-{{=jsonpath(inputs.parameters.task_payload, '$.out_basename')}}.bed"

          - name: execute-post-broad-peaks-file
            depends: "execute-compute-broad-bed-file-metadata"
            template: post-analysis-file
            arguments:
              parameters:
                - name: s3-key
                  value: "{{=jsonpath(inputs.parameters.task_payload, '$.out_s3_prefix')}}broad-{{=jsonpath(inputs.parameters.task_payload, '$.out_basename')}}.bed"
                - name: basename
                  value: "broad-{{inputs.parameters.out_basename}}"
                - name: file-size
                  value: "{{tasks.execute-compute-broad-bed-file-metadata.outputs.parameters.file-size}}"
                - name: md5sum
                  value: "{{tasks.execute-compute-broad-bed-file-metadata.outputs.parameters.md5sum}}"
                - name: experiment-id
                  value: "{{=jsonpath(inputs.parameters.task_payload, '$.experiment_id')}}"
                - name: assembly-id
                  value: "{{=jsonpath(inputs.parameters.task_payload, '$.assembly_id')}}"
                - name: analysis-type
                  value: "broad_peaks"

          - name: execute-write-gapped-peaks
            depends: "execute-genrich-chip-seq-broad-peaks.Succeeded"
            template: write-gapped-peaks
            arguments:
              parameters:
                - name: narrow-peaks-s3-prefix
                  value: "{{=jsonpath(inputs.parameters.task_payload, '$.out_s3_prefix')}}"
                - name: narrow-peaks-filename
                  value: "narrow-{{=jsonpath(inputs.parameters.task_payload, '$.out_basename')}}.bed"
                - name: broad-peaks-s3-prefix
                  value: "{{=jsonpath(inputs.parameters.task_payload, '$.out_s3_prefix')}}"
                - name: broad-peaks-filename
                  value: "broad-{{=jsonpath(inputs.parameters.task_payload, '$.out_basename')}}.bed"
                - name: gapped-peaks-s3-prefix
                  value: "{{=jsonpath(inputs.parameters.task_payload, '$.out_s3_prefix')}}"
                - name: gapped-peaks-filename
                  value: "gapped-{{=jsonpath(inputs.parameters.task_payload, '$.out_basename')}}.bed"

          - name: execute-compute-gapped-bed-file-metadata
            depends: "execute-write-gapped-peaks"
            templateRef:
              name: compute-file-metadata-v1-submittable
              template: compute-file-metadata
            arguments:
              parameters:
                - name: s3-key
                  value: "{{=jsonpath(inputs.parameters.task_payload, '$.out_s3_prefix')}}gapped-{{=jsonpath(inputs.parameters.task_payload, '$.out_basename')}}.bed"
                - name: filename
                  value: "gapped-{{inputs.parameters.out_basename}}.bed"

          - name: execute-post-gapped-peaks-file
            depends: "execute-compute-gapped-bed-file-metadata"
            template: post-analysis-file
            arguments:
              parameters:
                - name: s3-key
                  value: "{{=jsonpath(inputs.parameters.task_payload, '$.out_s3_prefix')}}gapped-{{=jsonpath(inputs.parameters.task_payload, '$.out_basename')}}.bed"
                - name: basename
                  value: "gapped-{{=jsonpath(inputs.parameters.task_payload, '$.out_basename')}}"
                - name: file-size
                  value: "{{tasks.execute-compute-gapped-bed-file-metadata.outputs.parameters.file-size}}"
                - name: md5sum
                  value: "{{tasks.execute-compute-gapped-bed-file-metadata.outputs.parameters.md5sum}}"
                - name: experiment-id
                  value: "{{=jsonpath(inputs.parameters.task_payload, '$.experiment_id')}}"
                - name: assembly-id
                  value: "{{=jsonpath(inputs.parameters.task_payload, '$.assembly_id')}}"
                - name: analysis-type
                  value: "gapped_peaks"

          - name: update-peak-calling-task-marker
            depends: >-
              (
                (
                  execute-genrich-chip-seq-broad-peaks.Skipped ||
                  execute-post-gapped-peaks-file
                ) ||
                check-work-avoidance-consistency.Failed
              )
            when: >-
              (
              ( {{inputs.parameters.force-update-task-markers}} == true
                && {{tasks.check-work-avoidance-consistency.status}} == Failed )
              || ( {{tasks.execute-genrich-chip-seq-broad-peaks.status}} == Skipped
                || {{tasks.execute-post-gapped-peaks-file.status}} == Succeeded )
              )
            templateRef:
              name: update-task-marker-v1-submittable
              template: update-task-marker
            arguments:
              parameters:
                - name: task-marker-s3-key
                  value: "{{tasks.compute-peak-calling-task-marker-name.outputs.result}}"
                - name: task-payload
                  value: "{{inputs.parameters.task_payload}}"

          - name: delete-peak-calling-pvc
            depends: >-
              (
                execute-compute-bed-file-metadata &&
                (
                  execute-genrich-chip-seq-broad-peaks.Skipped ||
                  (
                    execute-compute-narrow-bed-file-metadata &&
                    execute-compute-broad-bed-file-metadata
                  )
                )
              )
            templateRef:
              name: delete-patch-pvc-kubectl-v1-submittable
              template: delete-patch-pvc-kubectl
            arguments:
              parameters:
                - name: pvc-name
                  value: "{{tasks.create-peak-calling-pvc.outputs.parameters.pvc-name}}"
                - name: kubeconfig-path
                  value: "{{inputs.parameters.kubeconfig-path}}"


    - name: sort-alignments-by-queryname
      inputs:
        parameters:
          # Bam file as input
          - name: sort_alignment_params
          # PVC in which to store bedgraph
          - name: out-pvc-name
          - name: kubeconfig-path
      dag:
        tasks:
          - name: get-pvc-size
            templateRef:
              name: compute-pvc-size-v1-submittable
              template: compute-pvc-size
            arguments:
              parameters:
                - name: associated_files_size
                  value: "{{=jsonpath(inputs.parameters.sort_alignment_params, '$.file_size')}}"
                - name: size_factor
                  value: "1.25"

          - name: execute-sort-alignment-by-queryname
            depends: get-pvc-size
            templateRef:
              name: sort-alignment-by-queryname-pvc-callable-v1-submittable
              template: sort-alignment-by-queryname-pvc-callable
            arguments:
              parameters:
                - name: basename
                  value: "{{=jsonpath(inputs.parameters.sort_alignment_params, '$.basename')}}"
                - name: filename
                  value: "{{=jsonpath(inputs.parameters.sort_alignment_params, '$.filename')}}"
                - name: s3_key
                  value: "{{=jsonpath(inputs.parameters.sort_alignment_params, '$.s3_key')}}"
                - name: pvc-size
                  value: "{{tasks.get-pvc-size.outputs.parameters.pvc-size-formatted}}"
                - name: kubeconfig-path
                  value: "{{inputs.parameters.kubeconfig-path}}"
                - name: out-pvc-name
                  value: "{{inputs.parameters.out-pvc-name}}"


    - name: post-analysis-file
      retryStrategy:
        limit: "5"
        retryPolicy: "OnError"
      inputs:
        parameters:
          - name: s3-key
          - name: basename
          - name: file-size
          - name: md5sum
          - name: experiment-id
          - name: assembly-id
          - name: analysis-type
      script:
        image: ghcr.io/daugo/ensembl-reg-python:latest
        command: [ python ]
        source: |
          import sys
          import os
          import hashlib
          import json
          
          def main() -> int:
          
            post_data = {
              "experiment_id": "{{inputs.parameters.experiment-id}}",
              "assembly_id": "{{inputs.parameters.assembly-id}}",
              "analysis_type": "{{inputs.parameters.analysis-type}}",
              "file": {
                "file_type": "bed",
                "basename": "{{inputs.parameters.basename}}",
                "size": "{{inputs.parameters.file-size}}",
                "md5sum": "{{inputs.parameters.md5sum}}",
                "imported": False,
                "s3_object": {
                  "key": "{{inputs.parameters.s3-key}}",
                  "bucket_id": "085c4884-d0d6-4725-bda2-7463deed86eb"
                }
              }
            }
          
            print(json.dumps(post_data,  indent=2))
          
            return 0
          
          if __name__ == '__main__':
              sys.exit(main())

    - name: edit-genrich-input-filenames-formatted
      inputs:
        parameters:
          - name: task_payload
      script:
        image: ghcr.io/daugo/ensembl-reg-python:latest
        command: [ python ]
        source: |
          import sys
          import os
          import json
          from collections import defaultdict
          from pprint import pprint

          def main() -> int:
            task_payload_json = """{{inputs.parameters.task_payload}}"""
            task_payload_data = json.loads(task_payload_json)
          
            run_type_signal_filename = defaultdict(list)
            for s in task_payload_data['signals']:
              r_t = s['run_type']
              run_type_signal_filename[r_t].append(f"so_queryname_{s['basename']}.bam")
          
            run_type_control_filename = {}
            controls_run_types = []
            if 'controls' in task_payload_data.keys():
              for c in task_payload_data['controls']:
                r_t = c['run_type']
                controls_run_types.append(r_t)
                run_type_control_filename[r_t] = f"so_queryname_{c['basename']}.bam"
          
          
            assert len(set(controls_run_types)) == len(controls_run_types), "Duplicate run types in controls"
          
            signals_filenames_sorted = []
            controls_filenames_sorted = []
            for r_t, s_vals in run_type_signal_filename.items():
              signals_filenames_sorted.extend(s_vals)
              print(f"r_t: {r_t}, s_vals: {s_vals}")
          
              if r_t in run_type_control_filename.keys():
                controls_filenames_sorted.extend([run_type_control_filename[r_t]] * len(s_vals))
              else:
                controls_filenames_sorted.extend(["null"] * len(s_vals))
          
            pprint(f"signals_formatted: {','.join(signals_filenames_sorted)}")
            pprint(f"controls_formatted: {','.join(controls_filenames_sorted)}")
          
            with open("signals_files_formatted_str.txt", 'w') as f:
                f.write(','.join(signals_filenames_sorted))
          
            with open("controls_files_formatted_str.txt", 'w') as f:
              if run_type_control_filename:
                f.write(','.join(controls_filenames_sorted))
              else:
                f.write('')
          
            return 0
          
          
          if __name__ == '__main__':
              sys.exit(main())

      outputs:
        parameters:
          - name: signals_files_formatted_str
            valueFrom:
              path: signals_files_formatted_str.txt
          - name: controls_files_formatted_str
            valueFrom:
              path: controls_files_formatted_str.txt

    - name: genrich-chip-seq
      retryStrategy:
        limit: "5"
        backoff:
          duration: "10s"
          factor: "2"
          maxDuration: "12h"
        retryPolicy: "Always"
      inputs:
        parameters:
          - name: masked_regions_prefix
          - name: masked_regions_filename
          - name: q
          - name: signal_files_formatted_str
          - name: control_files_formatted_str
          - name: out_bed_filename
          - name: out_pileup_filename
          - name: out_pq_file_filename
          - name: out_s3_prefix
          - name: alignments-pvc
        artifacts:
          - name: masked-regions-file
            path: /mnt/vol/{{inputs.parameters.masked_regions_filename}}
            s3:
              key: "{{inputs.parameters.masked_regions_prefix}}{{inputs.parameters.masked_regions_filename}}"
      container:
        workingDir: /mnt/vol
        image: ghcr.io/daugo/ensembl-reg-genrich:latest
        command: [ bash, -c, -uef, -o, xtrace ]
        # TODO: Handle empty control_files_formatted_str \
        args: [ "ls -altrh \
                && SIGNAL_BAM_FILES={{inputs.parameters.signal_files_formatted_str}} \
                && CONTROL_BAM_FILES={{inputs.parameters.control_files_formatted_str}} \
                && echo Signal files: ${SIGNAL_BAM_FILES} \
                && echo Control files: ${CONTROL_BAM_FILES} \
                && Genrich \
                -t ${SIGNAL_BAM_FILES} \
                -c ${CONTROL_BAM_FILES} \
                -o {{inputs.parameters.out_bed_filename}} \
                -f {{inputs.parameters.out_pileup_filename}} \
                -k {{inputs.parameters.out_pq_file_filename}} \
                -r \
                -y \
                -q {{inputs.parameters.q}} \
                -s 20 \
                -e MT \
                -E {{inputs.parameters.masked_regions_filename}} \
                -v \
                && ls -altrh" ]
        resources:
          limits:
            cpu: 4900m
            memory: 45Gi
          requests:
            cpu: 4700m
            memory: 41Gi
        volumeMounts:
          - name: workdir
            mountPath: /mnt/vol
      volumes:
        - name: workdir
          persistentVolumeClaim:
            claimName: "{{inputs.parameters.alignments-pvc}}"
      outputs:
        artifacts:
          - name: final_bed
            path: /mnt/vol/{{inputs.parameters.out_bed_filename}}
            archive:
              none: { }
            s3:
              key: "{{inputs.parameters.out_s3_prefix}}{{inputs.parameters.out_bed_filename}}"
          - name: pileup
            path: /mnt/vol/{{inputs.parameters.out_pileup_filename}}
            s3:
              key: "{{inputs.parameters.out_s3_prefix}}{{inputs.parameters.out_pileup_filename}}.tgz"
          - name: pq_file
            path: /mnt/vol/{{inputs.parameters.out_pq_file_filename}}
            s3:
              key: "{{inputs.parameters.out_s3_prefix}}{{inputs.parameters.out_pq_file_filename}}.tgz"

    - name: genrich-chip-seq-broad-peaks
      retryStrategy:
        limit: "5"
        backoff:
          duration: "10s"
          factor: "2"
          maxDuration: "12h"
        retryPolicy: "Always"
      inputs:
        parameters:
          - name: masked_regions_prefix
          - name: masked_regions_filename
          - name: a
          - name: p_value_narrow
          - name: p_value_broad
          - name: pileup-pvc
          - name: pileup_filename
          - name: out_narrow_s3_prefix
          - name: out_narrow_bed_filename
          - name: out_broad_s3_prefix
          - name: out_broad_bed_filename
        artifacts:
          - name: masked-regions-file
            path: "/results/{{inputs.parameters.masked_regions_filename}}"
            s3:
              key: "{{inputs.parameters.masked_regions_prefix}}{{inputs.parameters.masked_regions_filename}}"
      container:
        workingDir: /mnt/vol
        image: ghcr.io/daugo/ensembl-reg-genrich:latest
        command: [ bash, -c, -uef, -o, xtrace ]
        args: [ "ls -altrh \
                && Genrich \
                -P \
                -o {{inputs.parameters.out_narrow_bed_filename}} \
                -f {{inputs.parameters.pileup_filename}} \
                -p {{inputs.parameters.p_value_narrow}} \
                -s 20
                -r \
                -y \
                -e MT \
                -E {{inputs.parameters.masked_regions_filename}} \
                -v \
                && ls -altrh
                && Genrich \
                -P \
                -o {{inputs.parameters.out_broad_bed_filename}} \
                -f {{inputs.parameters.pileup_filename}} \
                -g 200 \
                -a {{inputs.parameters.a}} \
                -p {{inputs.parameters.p_value_broad}} \
                -s 20 \
                -r \
                -y \
                -e MT \
                -E {{inputs.parameters.masked_regions_filename}} \
                -v \
                && ls -altrh 
                " ]
        resources:
          limits:
            cpu: 1900m
            memory: 1.5Gi
          requests:
            cpu: 900m
            memory: 1Gi
        volumeMounts:
          - name: workdir
            mountPath: /mnt/vol
      volumes:
        - name: workdir
          persistentVolumeClaim:
            claimName: "{{inputs.parameters.pileup-pvc}}"
      outputs:
        artifacts:
          - name: narrow_bed
            path: /mnt/vol/{{inputs.parameters.out_narrow_bed_filename}}
            archive:
              none: { }
            s3:
              key: "{{inputs.parameters.out_narrow_s3_prefix}}{{inputs.parameters.out_narrow_bed_filename}}"
          - name: broad_bed
            path: /mnt/vol/{{inputs.parameters.out_broad_bed_filename}}
            archive:
              none: { }
            s3:
              key: "{{inputs.parameters.out_broad_s3_prefix}}{{inputs.parameters.out_broad_bed_filename}}"

    - name: write-gapped-peaks
      retryStrategy:
        limit: "3"
        retryPolicy: "OnError"
      inputs:
        parameters:
          - name: narrow-peaks-filename
          - name: narrow-peaks-s3-prefix
          - name: broad-peaks-s3-prefix
          - name: broad-peaks-filename
          - name: gapped-peaks-s3-prefix
          - name: gapped-peaks-filename
        artifacts:
          - name: peaks_file
            path: "/results/{{inputs.parameters.narrow-peaks-filename}}"
            s3:
              key: "{{inputs.parameters.narrow-peaks-s3-prefix}}{{inputs.parameters.narrow-peaks-filename}}"
          - name: broad_peaks_file
            path: "/results/{{inputs.parameters.broad-peaks-filename}}"
            s3:
              key: "{{inputs.parameters.broad-peaks-s3-prefix}}{{inputs.parameters.broad-peaks-filename}}"
      container:
        workingDir: /results
        image: ghcr.io/daugo/ensembl-reg-gapped-peaks:latest
        command: [ bash, -c, -uef, -o, xtrace ]
        args: [ " ls -altrh \
              && SCRIPT_PATH=/usr/local/bin/writeGappedPeaks.py \
              && python ${SCRIPT_PATH} \
              {{inputs.parameters.broad-peaks-filename}} \
              {{inputs.parameters.narrow-peaks-filename}} \
              {{inputs.parameters.gapped-peaks-filename}}" ]
      outputs:
        artifacts:
          - name: gapped_peaks_file
            path: /results/{{inputs.parameters.gapped-peaks-filename}}
            archive:
              none: { }
            s3:
              key: "{{inputs.parameters.gapped-peaks-s3-prefix}}{{inputs.parameters.gapped-peaks-filename}}"
