# See the NOTICE file distributed with this work for additional information
# regarding copyright ownership.
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
# http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.
apiVersion: argoproj.io/v1alpha1
kind: WorkflowTemplate
metadata:
  name: check-s3-object-exists-v-0.1.0
spec:
  entrypoint: check-s3-object-exists

  templates:
    - name: check-s3-object-exists
      retryStrategy:
        limit: "5"
        backoff:
          duration: "10s"
          factor: "2"
        retryPolicy: "Always"
      inputs:
        parameters:
          - name: s3-endpoint
            value: "https://uk1s3.embassy.ebi.ac.uk"
          - name: bucket
            value: "ensembl-regulation-71319003-analysis-pipelines-b1"
          - name: s3-key
      script:
        env:
          - name: AWS_ACCESS_KEY_ID
            valueFrom:
              secretKeyRef:
                name: ensembl-regulation-s3embassy-credentials
                key: accessKey
          - name: AWS_SECRET_ACCESS_KEY
            valueFrom:
              secretKeyRef:
                name: ensembl-regulation-s3embassy-credentials
                key: secretKey
        image: dockerhub.ebi.ac.uk/ensreg/workflows/container-images/python-wf-helper:3.11.7_0.1.0
        command: [ python ]
        source: |
          import boto3 as boto3 
          from botocore.client import Config
          
          from warnings import warn
          import sys
          import os
          
          def _config_s3_client(endpoint):
            config = Config(
                read_timeout=900,
                connect_timeout=900, 
                retries={"max_attempts": 3}
            )
            session = boto3.session.Session()
          
            s3_client = session.client(
                service_name="s3",
                endpoint_url=endpoint,
            )
            return s3_client
          
          def s3_ls_names(s3_client, bucket, prefix):
            response = s3_client.list_objects_v2(Bucket=bucket, Prefix=prefix)
            return [o["Key"] for o in response["Contents"]]


          def main() -> int:
            s3_endpoint = "{{inputs.parameters.s3-endpoint}}"
          
            s3_client = _config_s3_client(s3_endpoint)

            bucket_name = "{{inputs.parameters.bucket}}"
            s3_object_key = "{{inputs.parameters.s3-key}}"
          
          
            try:
              retrieved_names = s3_ls_names(
                  s3_client,
                  bucket_name,
                  s3_object_key,
              )
          
              assert len(retrieved_names) == 1, f"Provided s3-key ({s3_object_key}) seems to be a prefix to multiple object keys"
              assert retrieved_names[0] == s3_object_key, f"Provided s3-key ({s3_object_key}) is not a exact match to any object."
          
              s3_object_exists = True
          
            except KeyError as e:
                warn(f'S3 Object {s3_object_key} not present in bucket {bucket_name}')
                s3_object_exists = False
          
            with open('s3_object_exists.txt', 'w') as f:
              if s3_object_exists:
                f.write("true")
              else:
                f.write("false")
          
            return 0

          if __name__ == '__main__':
              sys.exit(main())

      outputs:
        parameters:
          - name: s3-object-exists
            valueFrom:
              path: s3_object_exists.txt