# See the NOTICE file distributed with this work for additional information
# regarding copyright ownership.
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
# http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

apiVersion: argoproj.io/v1alpha1
kind: WorkflowTemplate
metadata:
  name: s3-prefix-objects-to-pvc-v1-submittable
spec:
  entrypoint: s3-prefix-objects-to-pvc
  imagePullSecrets:
    - name: ghcr-pull-token

  templates:
    - name: s3-prefix-objects-to-pvc
      inputs:
        parameters:
          - name: s3-prefix
          - name: pvc-name
          - name: pvc-dir
      dag:
        tasks:
          - name: s3-prefix-objects-to-pvc
            template: copy-s3-prefix-objects-to-pvc-boto3
            arguments:
              parameters:
                - name: s3-prefix
                  value: "{{inputs.parameters.s3-prefix}}"
                - name: pvc-name
                  value: "{{inputs.parameters.pvc-name}}"
                - name: pvc-dir
                  value: "{{inputs.parameters.pvc-dir}}"

    # TODO: Try this template instead of boto3 after updating AWs to 3.4.4
    # TODO: Add pvc-dir parameter
    - name: copy-s3-prefix-objects-to-pvc
      retryStrategy:
        limit: "5"
        backoff:
          duration: "10s"
          factor: "2"
        retryPolicy: "OnError"
      inputs:
        parameters:
          # S3 object location (Source)
          - name: s3-prefix
          # Destination
          - name: pvc-name
        artifacts:
          - name: run-alignments
            path: /results/
            s3:
              key: "{{inputs.parameters.s3-prefix}}"
      volumes:
        - name: workdir
          persistentVolumeClaim:
            claimName: '{{inputs.parameters.pvc-name}}'
      container:
        workingDir: /results
        imagePullPolicy: Always
        image: ghcr.io/daugo/ensembl-reg-bash:latest
        command: [ bash, -c, -ue, -o, xtrace ]
        args: [ "mkdir /mnt/vol/so_coordinates_runs_bam/ && mv *bam /mnt/vol/so_coordinates_runs_bam/ && ls -altrh && ls -altrh /mnt/vol/so_coordinates_runs_bam/" ]
        volumeMounts:
          - name: workdir
            mountPath: /mnt/vol

    - name: copy-s3-prefix-objects-to-pvc-boto3
      retryStrategy:
        limit: "6"
        backoff:
          duration: "10s"
          factor: "2"
        retryPolicy: "OnError"
      inputs:
        parameters:
          # Warning: bucket and endpoint hardcoded
          # S3 object location (Source)
          - name: s3-endpoint
            value: "https://uk1s3.embassy.ebi.ac.uk"
          - name: bucket
            value: "ensembl-regulation-71319003-analysis-pipelines-b1"
          - name: s3-prefix
          # Destination
          - name: pvc-name
          - name: pvc-dir
      volumes:
        - name: workdir
          persistentVolumeClaim:
            claimName: '{{inputs.parameters.pvc-name}}'
      script:
        env:
          - name: AWS_ACCESS_KEY_ID
            valueFrom:
              secretKeyRef:
                name: ensembl-regulation-s3embassy-credentials
                key: accessKey
          - name: AWS_SECRET_ACCESS_KEY
            valueFrom:
              secretKeyRef:
                name: ensembl-regulation-s3embassy-credentials
                key: secretKey
        workingDir: /mnt/vol
        image: ghcr.io/daugo/ensembl-reg-python:latest
        command: [ python ]
        source: |
          import boto3 as boto3 
          from botocore.client import Config

          from pathlib import Path
          import sys
          import os

          def _config_s3_client(endpoint):
            config = Config(
                read_timeout=5000,
                connect_timeout=5000, 
                retries={"max_attempts": 3}
            )
            session = boto3.session.Session()

            s3_client = session.client(
                service_name="s3",
                endpoint_url=endpoint,
            )
            return s3_client

          def s3_ls_names(s3_client, bucket, prefix):
              response = s3_client.list_objects_v2(Bucket=bucket, Prefix=prefix)
              return [o["Key"] for o in response["Contents"]]

          def main() -> int:
            s3_endpoint = "{{inputs.parameters.s3-endpoint}}"

            s3_client = _config_s3_client(s3_endpoint)

            bucket_name = "{{inputs.parameters.bucket}}"
            prefix= "{{inputs.parameters.s3-prefix}}"
          
            pvc_dir = "{{inputs.parameters.pvc-dir}}"
          
            response = s3_client.list_objects_v2(Bucket=bucket_name, Prefix=prefix)
            object_keys = [o["Key"] for o in response["Contents"]]

            for obj_k in object_keys:
              filename = Path(obj_k).name
              out_dir = Path('/mnt/vol') / f'{pvc_dir}'
              out_dir.mkdir(parents=True, exist_ok=True)
              print(f"Files in {out_dir} before transfer: {list(out_dir.iterdir())}")
              out_filepath = out_dir / filename
              s3_client.download_file(bucket_name, obj_k, str(out_filepath))
              print(f"Files in {out_dir} after transfer: {list(out_dir.iterdir())}")
          
            return 0

          if __name__ == '__main__':
              sys.exit(main())
        volumeMounts:
          - name: workdir
            mountPath: /mnt/vol